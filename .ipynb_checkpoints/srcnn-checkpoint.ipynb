{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b189974a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tensorflow\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.optimizers import Adam\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import numpy as np\n",
    "from noggin import create_plot\n",
    "import os\n",
    "import skimage\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c4d75bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(path):\n",
    "    for file in os.listdir(path):\n",
    "        img = cv2.imread(path + '/' + file)\n",
    "        img = cv2.normalize(img, None, alpha=0,beta=200, norm_type=cv2.NORM_MINMAX)\n",
    "        \n",
    "normalize('imgs/')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c4226767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving jw-image-1.jpg\n",
      "Saving jw-image-2.jpg\n",
      "Saving jw-image-3.jpg\n",
      "Saving jw-image-4.jpg\n"
     ]
    }
   ],
   "source": [
    "def interpolation(path, factor):\n",
    "    for file in os.listdir(path):\n",
    "        img = cv2.imread(path + '/' + file)\n",
    "        h, w, c = img.shape\n",
    "        new_height = int(h / factor)\n",
    "        new_width = int(w / factor)\n",
    "        \n",
    "        # resize the image - down\n",
    "        img = cv2.resize(img, (new_width, new_height), interpolation = cv2.INTER_LINEAR) #interploation are methods for resizing images;how do you go from image with 100px to 1000px \n",
    "        #bilinear interpolation\n",
    "        \n",
    "        # resize the image - up\n",
    "        img = cv2.resize(img, (w, h), interpolation = cv2.INTER_LINEAR)\n",
    "        \n",
    "        print('Saving {}'.format(file))\n",
    "        cv2.imwrite('bad/{}'.format(file), img)\n",
    "\n",
    "interpolation(\"imgs/\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "86df889a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(target,ref):\n",
    "    # the MSE between the two images is the sum of the squared difference between the two images\n",
    "    err=np.sum((target.astype('float')-ref.astype('float'))**2)\n",
    "    err=err/float(target.shape[0]*target.shape[1])#divided by total number of pixels\n",
    "    \n",
    "    return err\n",
    "\n",
    "#     target_data = np.array(target, dtype=float)\n",
    "#     ref_data = np.array(ref, dtype=float)\n",
    "\n",
    "#     diff = ref_data - target_data\n",
    "#     diff = diff.flatten('C')\n",
    "\n",
    "#     rmse = np.sqrt(np.mean(diff ** 2.))\n",
    "\n",
    "#     return 20 * np.log10(255. / rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a261bec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jw-image-1.jpg\n",
      "MSE: 377.30517054056463\n",
      "\n",
      "jw-image-2.jpg\n",
      "MSE: 125.78888088273251\n",
      "\n",
      "jw-image-3.jpg\n",
      "MSE: 220.87953881527062\n",
      "\n",
      "jw-image-4.jpg\n",
      "MSE: 153.04048387504105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir('bad/'):\n",
    "    \n",
    "    #open target and reference images\n",
    "    target=cv2.imread('bad/{}'.format(file))\n",
    "    ref = cv2.imread('imgs/{}'.format(file))\n",
    "    \n",
    "    #calculate scores\n",
    "    score = mse(target, ref)\n",
    "    \n",
    "    print('{}\\nMSE: {}\\n'.format(file, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "7738d33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def super_res():\n",
    "    SRCNN = Sequential()\n",
    "        \n",
    "    SRCNN.add(Conv2D(filters=128, kernel_size = (9, 9), kernel_initializer='glorot_uniform',\n",
    "                     activation='relu', padding='valid', use_bias=True, input_shape=(None, None, 1)))#only if in keras.json image_data_format is channels_last; else if channels_first then 1,None,None\n",
    "        \n",
    "    SRCNN.add(Conv2D(filters=64, kernel_size = (5, 5), kernel_initializer='glorot_uniform',\n",
    "                         activation='relu', padding='same', use_bias=True))\n",
    "        \n",
    "    SRCNN.add(Conv2D(filters=1, kernel_size = (5, 5), kernel_initializer='glorot_uniform',\n",
    "                         activation='linear', padding='valid', use_bias=True))\n",
    "        \n",
    "    SRCNN.compile(optimizer=Adam(lr=0.0003), loss=tf.keras.losses.MeanSquaredError(), metrics=['mean_squared_error'])\n",
    "    \n",
    "    return SRCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0f48e0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modcrop(img,scale):\n",
    "    #temp size\n",
    "    tmpsz=img.shape\n",
    "    sz=tmpsz[0:2]\n",
    "    \n",
    "    #ensures that dimension of our image are divisible by scale(doesn't leaves hanging remainders) by cropping the images size\n",
    "    #np.mod returns the remainder bewtween our sz and scale\n",
    "    sz=sz-np.mod(sz,scale)\n",
    "    \n",
    "    img=img[0:sz[0],1:sz[1]]\n",
    "    return img\n",
    "\n",
    "#crop offs the bordersize from all sides of the image\n",
    "def shave(image,border):\n",
    "    img=image[border: -border,border:-border]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e391dc6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "255\n"
     ]
    }
   ],
   "source": [
    "test = cv2.imread('bad/jw-image-1.jpg')\n",
    "\n",
    "print(np.min(test))\n",
    "print(np.max(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "8334572c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define main prediction function\n",
    "srcnn=super_res()\n",
    "def predict(image_path):\n",
    "    names = os.listdir(image_path)\n",
    "    names = sorted(names)\n",
    "    nums = names.__len__()\n",
    "    srcnn.load_weights(r\"C:\\Users\\tanay\\CogWorks\\SRCNN-keras\\SRCNN_check.h5\")\n",
    "    name = image_path + names[i]\n",
    "    hr_img = cv2.imread(name, cv2.IMREAD_COLOR)\n",
    "    hr_img = cv2.cvtColor(hr_img, cv2.COLOR_BGR2YCrCb)\n",
    "    hr_img = hr_img[:, :, 0]\n",
    "    shape = hr_img.shape\n",
    "     # two resize operation to produce training data and labels\n",
    "    lr_img = cv2.resize(hr_img, (int(shape[1] / scale), int(570 / 2)))\n",
    "    lr_img = cv2.resize(lr_img, (shape[1], shape[0]))\n",
    "    #load the srcnn model with weights cuz deep learning neural n/w take lot of time to train(have to feed in large amount of input data)\n",
    "#     \n",
    "     \n",
    "    #load the degraded and reference images\n",
    "    #in opencv, images are loaded as BGR channels\n",
    "#     path,file=os.path.split(image_path)\n",
    "#     degraded=cv2.imread(image_path)\n",
    "#     ref=cv2.imread('imgs/{}'.format(file))\n",
    "\n",
    "#     #preprocess the image with modcrop\n",
    "#     ref=modcrop(ref,3)#when calculating our image quality metrics later we have the same size image to what we produce in SRCNN network\n",
    "#     degraded=modcrop(degraded,3)\n",
    "    \n",
    "    #convert the image to YCrCb(3 channel image) - (srcnn trained on Y channel)\n",
    "    temp=cv2.cvtColor(degraded,cv2.COLOR_BGR2YCrCb)\n",
    "    #opencv does a very good job in converting from rgb to YCrCb and back\n",
    "    \n",
    "    #create image slice and normalize cuz SRCNN works on one dimensional input(or 3D inputs of depth 1 ,ie, inputs with one channel)\n",
    "    Y=np.zeros((1,temp.shape[0],temp.shape[1],1),dtype=float)\n",
    "    #create a numpy array the we fill with data,temp.shape[0]=width,[1]=height and last one means one channel(essentially like batch=1 cuz that's what going to get passed to the n/w ')\n",
    "    #fill in the data; all values are normalized to between 0 and 1 as that's how srcnn was trained\n",
    "    Y[0,:,:,0]=temp[:,:,0].astype(float)/255\n",
    "    #first 0 means 0th index(we are saying that batch size is 1); :,: means every point in these channels; last 0 means first channel,ie, all the pixels in first luminescence channel\n",
    "    #so we have our image slice, we have the Y channel, which is the first channel(index 0) out of the image that we converted to YCrCb color space\n",
    "    \n",
    "    #perform super-resolution with srcnn\n",
    "    pre=srcnn.predict(Y,batch_size=1)#that's why we had index 0  above cuz we are saying that batch size is 1\n",
    "    \n",
    "    #post-process output cuz pre is still normalized\n",
    "    pre*=255#multiplying every pixel by 255\n",
    "    pre[pre[:]>255]=255#any pixels >255 set it =255 to prevent any rounding errors due to multiplication\n",
    "    pre[pre[:]<0] =0# same reason as above\n",
    "    pre=pre.astype(np.uint8)#convert float back to int values\n",
    "    \n",
    "    #cuz this is only the luminescence channel in the pre ,SO\n",
    "    #copy Y channel back to image and convert to BGR\n",
    "    temp=shave(temp,6)#accd.to tutor it loses 3 pixels on each side so if we shave this with a border 6,we can crop it appropriately there, so it is the same size as our output\n",
    "    #if not agree with tutor, use print statements to see the specific dimensions\n",
    "    \n",
    "    # for the first channel(Y channel), copy in the output of our network\n",
    "    temp[:,:,0]=pre[0,:,:,0]\n",
    "    #So we are keeping the red difference and blue difference, channels 1 and 2, in this temp image which is in the YCrCb color space\n",
    "    #and in the first one we are copying in our ouput,our luminiscence channel\n",
    "    \n",
    "    #convert back to bgr\n",
    "    output=cv2.cvtColor(temp,cv2.COLOR_YCrCb2BGR)\n",
    "    \n",
    "    #emove borderfrom reference and degraded image, so that all our images(ref,degraded(low res.), and ouput(high res.)) are of the same size\n",
    "    ref = shave(ref.astype(np.uint8), 6)\n",
    "    degraded = shave(degraded.astype(np.uint8), 6)\n",
    "    \n",
    "    # image quality calculations\n",
    "    scores = []\n",
    "    scores.append(mse(degraded, ref))#degraded wrt ref\n",
    "    scores.append(mse(output, ref))#high res. output wrt ref\n",
    "    \n",
    "    # return images and scores\n",
    "    return ref, degraded, output, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "c8cc19f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_images(directory, output_directory, scaling_factor=2, max_nb_images=-1, true_upscale=False):\n",
    "    index = 1\n",
    "\n",
    "    if not os.path.exists(output_directory + \"X/\"):\n",
    "        os.makedirs(output_directory + \"X/\")\n",
    "\n",
    "    if not os.path.exists(output_directory + \"y/\"):\n",
    "        os.makedirs(output_directory + \"y/\")\n",
    "\n",
    "    # For each image in input_images directory\n",
    "    nb_images = len([name for name in os.listdir(directory)])\n",
    "\n",
    "    if max_nb_images != -1:\n",
    "        print(\"Transforming %d images.\" % max_nb_images)\n",
    "    else:\n",
    "        assert max_nb_images <= nb_images, \"Max number of images must be less than number of images in path\"\n",
    "        print(\"Transforming %d images.\" % (nb_images))\n",
    "\n",
    "    if nb_images == 0:\n",
    "        print(\"Extract the training images or images from imageset_91.zip (found in the releases of the project) \"\n",
    "              \"into a directory with the name 'input_images'\")\n",
    "        print(\"Extract the validation images or images from set5_validation.zip (found in the releases of the project) \"\n",
    "              \"into a directory with the name 'val_images'\")\n",
    "        exit()\n",
    "\n",
    "    for file in os.listdir(directory):\n",
    "        img = imread(directory + file, mode='RGB')\n",
    "\n",
    "        # Resize to 256 x 256\n",
    "        img = imresize(img, (img_size, img_size))\n",
    "\n",
    "        # Create patches\n",
    "        hr_patch_size = (16 * scaling_factor * _image_scale_multiplier)\n",
    "        nb_hr_images = (img_size ** 2) // (stride ** 2)\n",
    "\n",
    "        hr_samples = np.empty((nb_hr_images, hr_patch_size, hr_patch_size, 3))\n",
    "\n",
    "        image_subsample_iterator = subimage_generator(img, stride, hr_patch_size, nb_hr_images)\n",
    "\n",
    "        stride_range = np.sqrt(nb_hr_images).astype(int)\n",
    "\n",
    "        i = 0\n",
    "        for j in range(stride_range):\n",
    "            for k in range(stride_range):\n",
    "                hr_samples[i, :, :, :] = next(image_subsample_iterator)\n",
    "                i += 1\n",
    "\n",
    "        lr_patch_size = 16 * _image_scale_multiplier\n",
    "\n",
    "        t1 = time.time()\n",
    "        # Create nb_hr_images 'X' and 'Y' sub-images of size hr_patch_size for each patch\n",
    "        for i in range(nb_hr_images):\n",
    "            ip = hr_samples[i]\n",
    "            # Save ground truth image X\n",
    "            imsave(output_directory + \"/y/\" + \"%d_%d.png\" % (index, i + 1), ip)\n",
    "\n",
    "            # Apply Gaussian Blur to Y\n",
    "            op = gaussian_filter(ip, sigma=0.5)\n",
    "\n",
    "            # Subsample by scaling factor to Y\n",
    "            op = imresize(op, (lr_patch_size, lr_patch_size), interp='bicubic')\n",
    "\n",
    "            if not true_upscale:\n",
    "                # Upscale by scaling factor to Y\n",
    "                op = imresize(op, (hr_patch_size, hr_patch_size), interp='bicubic')\n",
    "\n",
    "            # Save Y\n",
    "            imsave(output_directory + \"/X/\" + \"%d_%d.png\" % (index, i+1), op)\n",
    "\n",
    "        print(\"Finished image %d in time %0.2f seconds. (%s)\" % (index, time.time() - t1, file))\n",
    "        index += 1\n",
    "\n",
    "        if max_nb_images > 0 and index >= max_nb_images:\n",
    "            print(\"Transformed maximum number of images. \")\n",
    "            break\n",
    "\n",
    "    print(\"Images transformed. Saved at directory : %s\" % (output_directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "b1443e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BLOCK_STEP = 16\n",
    "BLOCK_SIZE = 32\n",
    "Random_Crop = 30\n",
    "Patch_size = 32\n",
    "label_size = 20\n",
    "conv_side = 6\n",
    "scale = 2\n",
    "\n",
    "def prepare_data(_path):\n",
    "    names = os.listdir(_path)\n",
    "    names = sorted(names)\n",
    "    nums = names.__len__()\n",
    "\n",
    "    data = np.zeros((nums * Random_Crop, 1, Patch_size, Patch_size), dtype=np.double)\n",
    "    label = np.zeros((nums * Random_Crop, 1, label_size, label_size), dtype=np.double)\n",
    "\n",
    "    for i in range(nums):\n",
    "        name = _path + names[i]\n",
    "        hr_img = cv2.imread(name, cv2.IMREAD_COLOR)\n",
    "        shape = hr_img.shape\n",
    "\n",
    "        hr_img = cv2.cvtColor(hr_img, cv2.COLOR_BGR2YCrCb)\n",
    "        hr_img = hr_img[:, :, 0]\n",
    "\n",
    "        # two resize operation to produce training data and labels\n",
    "        lr_img = cv2.resize(hr_img, (int(shape[1] / scale), int(shape[0] / scale)))\n",
    "        lr_img = cv2.resize(lr_img, (shape[1], shape[0]))\n",
    "\n",
    "        # produce Random_Crop random coordinate to crop training img\n",
    "        Points_x = np.random.randint(0, min(shape[0], shape[1]) - Patch_size, Random_Crop)\n",
    "        Points_y = np.random.randint(0, min(shape[0], shape[1]) - Patch_size, Random_Crop)\n",
    "\n",
    "        for j in range(Random_Crop):\n",
    "            lr_patch = lr_img[Points_x[j]: Points_x[j] + Patch_size, Points_y[j]: Points_y[j] + Patch_size]\n",
    "            hr_patch = hr_img[Points_x[j]: Points_x[j] + Patch_size, Points_y[j]: Points_y[j] + Patch_size]\n",
    "\n",
    "            lr_patch = lr_patch.astype(float) / 255.\n",
    "            hr_patch = hr_patch.astype(float) / 255.\n",
    "\n",
    "            data[i * Random_Crop + j, 0, :, :] = lr_patch\n",
    "            label[i * Random_Crop + j, 0, :, :] = hr_patch[conv_side: -conv_side, conv_side: -conv_side]\n",
    "            # cv2.imshow(\"lr\", lr_patch)\n",
    "            # cv2.imshow(\"hr\", hr_patch)\n",
    "            # cv2.waitKey(0)\n",
    "    return data, label\n",
    "\n",
    "def prepare_crop_data(_path):\n",
    "    names = os.listdir(_path)\n",
    "    names = sorted(names)\n",
    "    nums = names.__len__()\n",
    "\n",
    "    data = []\n",
    "    label = []\n",
    "\n",
    "    for i in range(nums):\n",
    "        name = _path + names[i]\n",
    "        hr_img = cv2.imread(name, cv2.IMREAD_COLOR)\n",
    "        hr_img = cv2.cvtColor(hr_img, cv2.COLOR_BGR2YCrCb)\n",
    "        hr_img = hr_img[:, :, 0]\n",
    "        shape = hr_img.shape\n",
    "        print(shape)\n",
    "\n",
    "        # two resize operation to produce training data and labels\n",
    "        lr_img = cv2.resize(hr_img, (int(shape[1] / scale), int(570 / 2)))\n",
    "        lr_img = cv2.resize(lr_img, (shape[1], shape[0]))\n",
    "\n",
    "        width_num = int((shape[0] - (BLOCK_SIZE - BLOCK_STEP) * 2) / BLOCK_STEP)\n",
    "        height_num = int((shape[1] - (BLOCK_SIZE - BLOCK_STEP) * 2) / BLOCK_STEP)\n",
    "        for k in range(width_num):\n",
    "            for j in range(height_num):\n",
    "                x = k * BLOCK_STEP\n",
    "                y = j * BLOCK_STEP\n",
    "                hr_patch = hr_img[x: x + BLOCK_SIZE, y: y + BLOCK_SIZE]\n",
    "                lr_patch = lr_img[x: x + BLOCK_SIZE, y: y + BLOCK_SIZE]\n",
    "\n",
    "                lr_patch = lr_patch.astype(float) / 255.\n",
    "                hr_patch = hr_patch.astype(float) / 255.\n",
    "\n",
    "                lr = np.zeros((1, Patch_size, Patch_size), dtype=np.double)\n",
    "                hr = np.zeros((1, label_size, label_size), dtype=np.double)\n",
    "\n",
    "                lr[0, :, :] = lr_patch\n",
    "                hr[0, :, :] = hr_patch[conv_side: -conv_side, conv_side: -conv_side]\n",
    "\n",
    "                data.append(lr)\n",
    "                label.append(hr)\n",
    "\n",
    "    data = np.array(data, dtype=float)\n",
    "    label = np.array(label, dtype=float)\n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "8c8dd952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 500)\n",
      "(512, 512)\n",
      "(576, 720)\n",
      "(288, 288)\n",
      "(256, 256)\n",
      "(288, 352)\n",
      "(361, 250)\n",
      "(276, 276)\n",
      "(362, 500)\n",
      "(288, 352)\n",
      "(280, 280)\n",
      "(512, 512)\n",
      "(512, 768)\n",
      "(512, 512)\n",
      "(656, 529)\n",
      "(344, 228)\n",
      "(391, 586)\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "import h5py\n",
    "\n",
    "def write_hdf5(data, labels, output_filename):\n",
    "    \"\"\"\n",
    "    This function is used to save image data and its label(s) to hdf5 file.\n",
    "    output_file.h5,contain data and label\n",
    "    \"\"\"\n",
    "\n",
    "    x = data.astype(np.float32)\n",
    "    y = labels.astype(np.float32)\n",
    "\n",
    "    with h5py.File(output_filename, 'w') as h:\n",
    "        h.create_dataset('data', data=x, shape=x.shape)\n",
    "        h.create_dataset('label', data=y, shape=y.shape)\n",
    "        # h.create_dataset()\n",
    "\n",
    "\n",
    "def read_training_data(file):\n",
    "    with h5py.File(file, 'r') as hf:\n",
    "        data = np.array(hf.get('data'))\n",
    "        label = np.array(hf.get('label'))\n",
    "        train_data = np.transpose(data, (0, 2, 3, 1))\n",
    "        train_label = np.transpose(label, (0, 2, 3, 1))\n",
    "        return train_data, train_label\n",
    "    \n",
    "data, label = prepare_crop_data(\"source/\")\n",
    "write_hdf5(data, label, \"crop_train.h5\")\n",
    "data, label = prepare_data(\"imgs/\")\n",
    "write_hdf5(data, label, \"test.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "f1a73506",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "im = Image.fromarray(output[:,:,::-1])\n",
    "im.save(\"bad/jw-image.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "f3d73813",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [208]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m ModelCheckpoint(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSRCNN_check.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      5\u001b[0m                                  save_weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m callbacks_list \u001b[38;5;241m=\u001b[39m [checkpoint]\n\u001b[1;32m----> 8\u001b[0m \u001b[43msrcnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_label\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\week2\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\week2\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\week2\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\week2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\week2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\week2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\week2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\week2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\week2\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data, label = read_training_data(\"./crop_train.h5\")\n",
    "val_data, val_label = read_training_data(\"./test.h5\")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"SRCNN_check.h5\", monitor='val_loss', verbose=1, save_best_only=True,\n",
    "                                 save_weights_only=False, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "srcnn.fit(data, label, batch_size=28, validation_data=(val_data, val_label),\n",
    "                    callbacks=callbacks_list, shuffle=True, epochs=3, verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "e1eb15aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "mse2 = tf.keras.losses.MeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "668281b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotADirectoryError",
     "evalue": "[WinError 267] The directory name is invalid: 'C:\\\\Users\\\\tanay\\\\CogWorks\\\\Image-Restoration-using-SRCNN\\\\bad\\\\jw-image-1.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "Input \u001b[1;32mIn [229]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ref, degraded, output,scores\u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mUsers\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mtanay\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mCogWorks\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mImage-Restoration-using-SRCNN\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mbad\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mjw-image-1.jpg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# print all scores for all images\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDegraded Image: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMSE: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(scores[\u001b[38;5;241m0\u001b[39m]))\n",
      "Input \u001b[1;32mIn [221]\u001b[0m, in \u001b[0;36mpredict\u001b[1;34m(image_path)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(image_path):\n\u001b[1;32m----> 4\u001b[0m     names \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(names)\n\u001b[0;32m      6\u001b[0m     nums \u001b[38;5;241m=\u001b[39m names\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__len__\u001b[39m()\n",
      "\u001b[1;31mNotADirectoryError\u001b[0m: [WinError 267] The directory name is invalid: 'C:\\\\Users\\\\tanay\\\\CogWorks\\\\Image-Restoration-using-SRCNN\\\\bad\\\\jw-image-1.jpg'"
     ]
    }
   ],
   "source": [
    "ref, degraded, output,scores= predict(r\"C:\\Users\\tanay\\CogWorks\\Image-Restoration-using-SRCNN\\bad\\jw-image-1.jpg\")\n",
    "# print all scores for all images\n",
    "print('Degraded Image: \\nMSE: {}\\n'.format(scores[0]))\n",
    "print('Reconstructed Image: \\nMSE: {}\\n'.format(scores[1]))\n",
    "\n",
    "\n",
    "# display images as subplots\n",
    "fig, axs = plt.subplots(1, 3, figsize=(20, 8))#1 row,3 columns\n",
    "axs[0].imshow(cv2.cvtColor(ref, cv2.COLOR_BGR2RGB))#first subplot\n",
    "#imshow assumes RGB images but cv2 loads images as BGR else channel mixing will take place and we will get weird images\n",
    "axs[0].set_title('Original')\n",
    "axs[1].imshow(cv2.cvtColor(degraded, cv2.COLOR_BGR2RGB))#2nd subplot\n",
    "axs[1].set_title('Degraded')\n",
    "axs[2].imshow(cv2.cvtColor(output, cv2.COLOR_BGR2RGB))\n",
    "axs[2].set_title('SRCNN')\n",
    "\n",
    "\n",
    "# remove the x and y ticks\n",
    "for ax in axs:\n",
    "    ax.set_xticks([])#leave them blank to remove ticks\n",
    "    ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9b8518fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 20  19  21]\n",
      "  [ 20  19  21]\n",
      "  [ 19  18  20]\n",
      "  ...\n",
      "  [140  94  83]\n",
      "  [104  55  45]\n",
      "  [106  55  45]]\n",
      "\n",
      " [[ 20  19  21]\n",
      "  [ 20  19  21]\n",
      "  [ 20  19  21]\n",
      "  ...\n",
      "  [141  95  84]\n",
      "  [105  56  46]\n",
      "  [108  55  45]]\n",
      "\n",
      " [[ 21  20  22]\n",
      "  [ 21  20  22]\n",
      "  [ 21  20  22]\n",
      "  ...\n",
      "  [124  75  65]\n",
      "  [102  51  41]\n",
      "  [105  52  42]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 20  19  29]\n",
      "  [ 22  21  31]\n",
      "  [ 20  19  29]\n",
      "  ...\n",
      "  [ 27  25  47]\n",
      "  [ 29  27  49]\n",
      "  [ 29  27  49]]\n",
      "\n",
      " [[ 18  17  26]\n",
      "  [ 18  17  26]\n",
      "  [ 19  18  27]\n",
      "  ...\n",
      "  [ 25  23  45]\n",
      "  [ 25  23  45]\n",
      "  [ 25  23  45]]\n",
      "\n",
      " [[ 18  17  26]\n",
      "  [ 18  17  26]\n",
      "  [ 19  18  27]\n",
      "  ...\n",
      "  [ 25  23  45]\n",
      "  [ 25  23  45]\n",
      "  [ 23  23  47]]]\n",
      "1005\n"
     ]
    }
   ],
   "source": [
    "train_images = []\n",
    "train_truth = []\n",
    "for file in os.listdir('imgs/'):\n",
    "    target=cv2.imread('bad/{}'.format(file))\n",
    "    ref = cv2.imread('imgs/{}'.format(file))\n",
    "    \n",
    "    train_images.append(target)\n",
    "    train_truth.append(ref)\n",
    "\n",
    "print(train_images[0])\n",
    "print(len(train_truth[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ce8b86ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\tanay\\anaconda3\\envs\\week2\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\tanay\\anaconda3\\envs\\week2\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\tanay\\anaconda3\\envs\\week2\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\tanay\\anaconda3\\envs\\week2\\lib\\site-packages\\keras\\engine\\training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\tanay\\anaconda3\\envs\\week2\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer \"conv2d_186\" (type Conv2D).\n    \n    Negative dimension size caused by subtracting 9 from 3 for '{{node sequential_62/conv2d_186/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](sequential_62/Cast, sequential_62/conv2d_186/Conv2D/ReadVariableOp)' with input shapes: [570,985,3,1], [9,9,1,128].\n    \n    Call arguments received by layer \"conv2d_186\" (type Conv2D):\n      • inputs=tf.Tensor(shape=(570, 985, 3, 1), dtype=float32)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [122]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43msrcnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\week2\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filef4yp_7nd.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\tanay\\anaconda3\\envs\\week2\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\tanay\\anaconda3\\envs\\week2\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\tanay\\anaconda3\\envs\\week2\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\tanay\\anaconda3\\envs\\week2\\lib\\site-packages\\keras\\engine\\training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\tanay\\anaconda3\\envs\\week2\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer \"conv2d_186\" (type Conv2D).\n    \n    Negative dimension size caused by subtracting 9 from 3 for '{{node sequential_62/conv2d_186/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](sequential_62/Cast, sequential_62/conv2d_186/Conv2D/ReadVariableOp)' with input shapes: [570,985,3,1], [9,9,1,128].\n    \n    Call arguments received by layer \"conv2d_186\" (type Conv2D):\n      • inputs=tf.Tensor(shape=(570, 985, 3, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "srcnn.fit(train_images[0],\n",
    "                                 steps_per_epoch=1,\n",
    "                                 epochs=3)\n",
    "# for epoch in range(3):\n",
    "#     loss = []\n",
    "#     for file in os.listdir('bad/'):\n",
    "\n",
    "#         # perform super-resolution\n",
    "#         ref, degraded, output, scores = predict('bad/{}'.format(file))\n",
    "\n",
    "#         # display images as subplots\n",
    "#         fig, axs = plt.subplots(1, 3, figsize=(20, 8))\n",
    "#         axs[0].imshow(cv2.cvtColor(ref, cv2.COLOR_BGR2RGB))\n",
    "#         axs[0].set_title('Original')\n",
    "#         axs[1].imshow(cv2.cvtColor(degraded, cv2.COLOR_BGR2RGB))\n",
    "#         axs[1].set_title('Degraded')\n",
    "#         axs[1].set(xlabel = 'MSE: {}\\n'.format(scores[0]))\n",
    "#         axs[2].imshow(cv2.cvtColor(output, cv2.COLOR_BGR2RGB))\n",
    "#         axs[2].set_title('SRCNN')\n",
    "#         axs[2].set(xlabel = 'MSE: {}\\n'.format(scores[1]))\n",
    "\n",
    "#         # remove the x and y ticks\n",
    "#         for ax in axs:\n",
    "#             ax.set_xticks([])\n",
    "#             ax.set_yticks([])\n",
    "            \n",
    "#         loss.append(scores[1])\n",
    "        \n",
    "#     np.array(loss)\n",
    "\n",
    "\n",
    "      \n",
    "#     print('Saving {}'.format(file))\n",
    "#     fig.savefig('output/{}.png'.format(os.path.splitext(file)[0])) \n",
    "#     plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a38c9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23529fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
