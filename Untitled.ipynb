{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b189974a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tensorflow\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from noggin import create_plot\n",
    "import os\n",
    "import skimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7738d33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def super_res():\n",
    "    SRCNN = Sequential()\n",
    "        \n",
    "    SRCNN.add(Conv2D(filters=128, kernel_size = (9, 9), kernel_initializer='glorot_uniform',\n",
    "                     activation='relu', padding='valid', use_bias=True, input_shape=(None, None, 1)))#only if in keras.json image_data_format is channels_last; else if channels_first then 1,None,None\n",
    "        \n",
    "    SRCNN.add(Conv2D(filters=64, kernel_size = (3, 3), kernel_initializer='glorot_uniform',\n",
    "                         activation='relu', padding='same', use_bias=True))\n",
    "        \n",
    "    SRCNN.add(Conv2D(filters=1, kernel_size = (5, 5), kernel_initializer='glorot_uniform',\n",
    "                         activation='linear', padding='valid', use_bias=True))\n",
    "        \n",
    "    SRCNN.compile(optimizer=Adam(lr=0.0003), loss='mean_squared_error', metrics=['mean_squared_error'])\n",
    "    \n",
    "    return SRCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "80cf111b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to open file (unable to open file: name = '3051crop_weight_200.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m super_res()\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m3051crop_weight_200.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m plotter, fig, ax \u001b[38;5;241m=\u001b[39m create_plot([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\week2\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\week2\\lib\\site-packages\\h5py\\_hl\\files.py:533\u001b[0m, in \u001b[0;36mFile.__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, **kwds)\u001b[0m\n\u001b[0;32m    525\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[0;32m    526\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[0;32m    527\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[0;32m    528\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[0;32m    529\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    530\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[0;32m    531\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[0;32m    532\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[1;32m--> 533\u001b[0m     fid \u001b[38;5;241m=\u001b[39m make_fid(name, mode, userblock_size, fapl, fcpl, swmr\u001b[38;5;241m=\u001b[39mswmr)\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\week2\\lib\\site-packages\\h5py\\_hl\\files.py:226\u001b[0m, in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[0;32m    225\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[1;32m--> 226\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    228\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[1;32mh5py\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\h5f.pyx:106\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to open file (unable to open file: name = '3051crop_weight_200.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "model = super_res()\n",
    "model.load_weights(\"3051crop_weight_200.h5\")\n",
    "\n",
    "\n",
    "plotter, fig, ax = create_plot([\"loss\", \"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c605a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "for epoch_cnt in range(1):\n",
    "    idxs = np.arange(len(x_train))\n",
    "    np.random.shuffle(idxs)  \n",
    "\n",
    "    for batch_cnt in range(len(x_train) // batch_size):\n",
    "        batch_indices = idxs[batch_cnt * batch_size : (batch_cnt + 1) * batch_size]\n",
    "        \n",
    "        batch = x_train[batch_indices] \n",
    "        truth = y_train[batch_indices]  \n",
    "        \n",
    "        # compute your model's predictions for this batch\n",
    "        prediction = model(batch)  # <COGSTUB>\n",
    "\n",
    "        # compute the loss that compares the model's predictions to the true values\n",
    "        loss = softmax_crossentropy(prediction, truth)  # <COGSTUB>  use softmax_cross_entropy\n",
    "\n",
    "        # Use mygrad compute the derivatives for your model's parameters, so\n",
    "        # that we can perform gradient descent.\n",
    "        loss.backward()  # <COGLINE>\n",
    "\n",
    "        # execute one step of gradient descent by calling optim.step()\n",
    "        optim.step()  # <COGLINE>\n",
    "\n",
    "        # compute the accuracy between the prediction and the truth\n",
    "        acc = accuracy(prediction, truth)  # <COGSTUB>\n",
    "\n",
    "        # set the training loss and accuracy\n",
    "        plotter.set_train_batch(\n",
    "            {\"loss\": loss.item(), \"accuracy\": acc}, batch_size=batch_size\n",
    "        )\n",
    "\n",
    "    # Here, we evaluate our model on batches of *testing* data\n",
    "    # this will show us how good our model does on data that\n",
    "    # it has never encountered\n",
    "    # Iterate over batches of *testing* data\n",
    "    for batch_cnt in range(0, len(x_test) // batch_size):\n",
    "        idxs = np.arange(len(x_test))\n",
    "        batch_indices = idxs[batch_cnt * batch_size : (batch_cnt + 1) * batch_size]  # <COGSTUB>  get the batch of our **test** data\n",
    "        batch = x_test[batch_indices]  # <COGSTUB>  get the batch of our **test** labels\n",
    "\n",
    "        with mg.no_autodiff:\n",
    "            # get your model's prediction on the test-batch\n",
    "            prediction = model(batch)  # <COGSTUB>\n",
    "\n",
    "            # get the truth values for that test-batch\n",
    "            truth = y_test[batch_indices]  # <COGSTUB>\n",
    "\n",
    "            # compute the test accuracy\n",
    "            acc = accuracy(prediction, truth)  # <COGSTUB>\n",
    "\n",
    "        # log the test-accuracy in noggin\n",
    "        plotter.set_test_batch({\"accuracy\": acc}, batch_size=batch_size)\n",
    "\n",
    "    plotter.set_train_epoch()\n",
    "    plotter.set_test_epoch()\n",
    "plotter.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
